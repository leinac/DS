{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning from Blood Donations Prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Introduction**\n",
    "\n",
    "Blood transfusion saves lives - from replacing lost blood during major surgery or a serious injury to treating various illnesses and blood disorders. Ensuring that there's enough blood in supply whenever needed is a serious challenge for the health professionals. The demand for blood fluctuates throughout the year. As one prominent example, blood donations slow down during busy holiday seasons. An accurate forecast for the future supply of blood allows for an appropriate action to be taken ahead of time and therefore saving more lives.\n",
    "\n",
    "Aim Of Project:\n",
    "\n",
    "To build a model which can identify who is likely to donate blood again using TPOT. TPOT can eliminate the most tedious part of machine learning seemlessly and effortlessly more than ever.\n",
    "\n",
    "You can reach TPOT website and documentation from [TPOT](http://epistasislab.github.io/tpot/).\n",
    "\n",
    "Let's get started exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score\n",
    "\n",
    "#Importing library for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the unwanted warning\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **Loading the blood donations data**\n",
    "\n",
    "We now know that we are working with a typical CSV file (i.e., the delimiter is ,, etc.). We proceed to loading the data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Lets get started exploring the data.\n",
    "\n",
    "train = pd.read_csv(\"../input/predicting-blood-analysis/blood-train.csv\")\n",
    "test=pd.read_csv(\"../input/predicting-blood-analysis/blood-test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) **Inspecting transfusion DataFrame**\n",
    "\n",
    "The RFM model stands for Recency, Frequency and Monetary Value and it is commonly used in marketing for identifying the best customers. In this case, the customers are blood donors.\n",
    "\n",
    "RFMTC is a variation of the RFM model. Below is a description of what each column means in the dataset:\n",
    "\n",
    "R (Recency - months since the last donation)\n",
    "F (Frequency - total number of donation)\n",
    "M (Monetary - total volume blood donated in c.c.)\n",
    "T (Time - months since the first donation)\n",
    "a binary variable representing whether he/she donated blood in March 2007 (1 stands for donating blood; 0 stands for not donating blood)\n",
    "It will be helpful to rename these columns as such; except for the last column, which will be the Target column, as the aim is to predict whether someone donated blood in March 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the train and test size\n",
    "print(\"Train Shape : \",train.shape)\n",
    "print(\"Test Shape : \",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "\n",
    "> We can see that there are 576 rows and 6 columns in our training dataset\n",
    "\n",
    "> We can see that there are 200 rows and 5 columns in our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a concise summary of transfusion DataFrame\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "\n",
    "> We can see that there is no missing vale for any row.\n",
    "\n",
    "> The datatype for all features is integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Creating target column**\n",
    "\n",
    "We are aiming to predict the value in whether he/she donated blood in March 2007 column. Let's rename this it to target so that it's more convenient to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename target column as 'target' for brevity\n",
    "train.rename(\n",
    "    columns={'Made Donation in March 2007':'Target'},\n",
    "    inplace=True\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.**Checking target incidence**\n",
    "\n",
    "We want to predict whether or not the same donor will give blood the next time the vehicle comes to campus. The model for this is a binary classifier, meaning that there are only 2 possible outcomes:\n",
    "\n",
    "0 - the donor will not give blood\n",
    "1 - the donor will give blood\n",
    "Target incidence is defined as the number of cases of each individual target value in a dataset. That is, how many 0s in the target column compared to how many 1s? Target incidence gives us an idea of how balanced (or imbalanced) is our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting the number of people who donated and not donated\n",
    "train[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "> This is an imbalance dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) **Looking into the testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "> Made Donation in March 2007 is not present in Test data.\n",
    "\n",
    "> We have to train our classifier using the Train data and generate predictions (Made Donation in March 2007) on Test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "\n",
    "> We can see that there is no missing vale for any row.\n",
    "> \n",
    "> The datatype for all features is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Exploration**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) **Describing training dataset**\n",
    "\n",
    "describe() method can show different values like count, mean, standard deviation, etc. of numeric data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of the data\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot for Months since Last Donation\n",
    "plt.figure(figsize=(20,10)) \n",
    "sns.boxplot(y=\"Months since Last Donation\",data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "> We can see that most of donations happened around 10th month\n",
    "> There are some outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation between all variables [Checking how different variable are related]\n",
    "corrmat=train.corr()\n",
    "f, ax = plt.subplots(figsize =(9, 8)) \n",
    "sns.heatmap(corrmat, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1,fmt = \".2f\",annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "Heatmap of Correlation between different features:\n",
    "\n",
    "Positive numbers = Positive correlation, i.e. increase in one feature will increase the other feature & vice-versa.\n",
    "Negative numbers = Negative correlation, i.e. increase in one feature will decrease the other feature & vice-versa.\n",
    "\n",
    "In our case, we focus on which features have strong positive or negative correlation with the Target feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Splitting dataset into train and test datasets**\n",
    "\n",
    "We'll now use train_test_split() method to split DataFrame.This is very easy to do using the train_test_split() method from the scikit learn library - all we need to do is specify the stratify parameter. In our case, we'll stratify on the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split method\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split transfusion DataFrame into\n",
    "# X_train, X_test, y_train and y_test datasets,\n",
    "# stratifying on the `target` column\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train.drop(columns=['Target','Unnamed: 0']),\n",
    "    train.Target,\n",
    "    test_size=0.2,\n",
    "    random_state=0)"
   ]
  },
  {
   "attachments": {
    "download.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **Selecting model using TPOT**\n",
    "\n",
    "TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.\n",
    "![download.png](attachment:download.png)\n",
    "\n",
    "TPOT will automatically explore hundreds of possible pipelines to find the best one for our dataset. Note, the outcome of this search will be a scikit-learn pipeline, meaning it will include any pre-processing steps as well as the model.\n",
    "\n",
    "We are using TPOT to help us zero in on one model that we can then explore and optimize further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TPOTClassifier and roc_auc_score\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Instantiate TPOTClassifier\n",
    "tpot = TPOTClassifier(\n",
    "    generations=5,\n",
    "    population_size=20,\n",
    "    verbosity=2,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    disable_update_check=True,\n",
    "    config_dict='TPOT light'\n",
    ")\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# AUC score for tpot model\n",
    "tpot_auc_score = roc_auc_score(y_test, tpot.predict_proba(X_test)[:, 1])\n",
    "print(f'\\nAUC score: {tpot_auc_score:.4f}')\n",
    "\n",
    "\n",
    "# Print best pipeline steps\n",
    "print('\\nBest pipeline steps:', end='\\n')\n",
    "for idx, (name, transform) in enumerate(tpot.fitted_pipeline_.steps, start=1):\n",
    "    # Print idx and transform\n",
    "    print(f'{idx}. {transform}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPOT picked LogisticRegression as the best model for our dataset with no pre-processing , giving us the AUC score of 0.8042. This is a great starting point. Let's see if we can make it better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Training the linear regression model¶\n",
    "\n",
    "We are now ready to train the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Instantiate LogisticRegression\n",
    "logreg = LogisticRegression(C=25.0, random_state=42)\n",
    "#Fitting the model\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on the test data\n",
    "pred=logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the confusion matrix\n",
    "confusion_matrix(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC score for tpot model\n",
    "logreg_auc_score = roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1])\n",
    "print(f'\\nAUC score: {logreg_auc_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. **Conclusion**\n",
    "\n",
    "In this notebook, we explored automatic model selection using TPOT and AUC score we got was 0.8042. This is better than simply choosing 0 all the time (the target incidence suggests that such a model would have 76% success rate). If you plan to use TPOT in the future, I strongly suggest you look at its excellent [documentation](http://epistasislab.github.io/tpot/). You can further improve the auc score by removing outliers as logistic regression is sensitive to outliers. Thus, removing outliers can further improve it.\n",
    "\n",
    "Thank you for reading my notebook,please upvote it if you like it.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
